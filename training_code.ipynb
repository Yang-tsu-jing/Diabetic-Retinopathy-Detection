{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160cc081-915e-4111-9748-8709f41b8ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DSP523\\AppData\\Local\\Temp\\ipykernel_5388\\3601183918.py:12: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import *\n",
    "from function import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49c0a5eb-230f-4609-b8c2-d295efaff607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f049ac3-e6d9-457b-8e96-e0c1df10195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41df0ff-1e55-4159-aa9f-da8f4e72f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = trainDataset('retina-train', 'train_labels.csv', train_tfm)\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "train_set, valid_set = torch.utils.data.random_split(train_set, [train_set_size, len(train_set) - train_set_size])\n",
    "\n",
    "test_set = testDataset('retina-test', train_tfm)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7352b7a8-0568-436f-a05a-a56c26a5ac65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:09<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 10 | train_accs = 0.579136690647482 & train_loss = 0.030703417688822576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.03213127092881636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:09<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10 | train_accs = 0.579136690647482 & train_loss = 0.030586947318461302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.032124124645616446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:11<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 10 | train_accs = 0.579136690647482 & train_loss = 0.03056955044503978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.03211496036018481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:10<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 10 | train_accs = 0.579136690647482 & train_loss = 0.030558949394477643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 10.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.0321079214509024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:09<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 10 | train_accs = 0.579136690647482 & train_loss = 0.030553249253643503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.032104353442716824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:09<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 10 | train_accs = 0.579136690647482 & train_loss = 0.030551064822027723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.03210309418764981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:09<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 10 | train_accs = 0.579136690647482 & train_loss = 0.030550397271446757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.03210268707937031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:10<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 10 | train_accs = 0.579136690647482 & train_loss = 0.03057915683415868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.03209041322817643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:10<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 10 | train_accs = 0.579136690647482 & train_loss = 0.03054337485802831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.032092834488626876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:09<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 10 | train_accs = 0.579136690647482 & train_loss = 0.03054142916659943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 10 | validation_accs = 0.5956937799043063 & validation_loss = 0.032093241026527004\n"
     ]
    }
   ],
   "source": [
    "model = Classification(3, 3)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "softmax = nn.Softmax(dim = -1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    train_accs = 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        imgs, labels = batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "     \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        train_accs += (preds == labels).sum().item()\n",
    "    scheduler.step()\n",
    "    print(f'Epoch {epoch+1} / {epochs} | train_accs = {train_accs / total} & train_loss = {train_loss / total}')\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_accs = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            imgs, labels = batch\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "            _, preds= torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            valid_accs += (preds == labels).sum().item()\n",
    "\n",
    "    print(f'Epoch {epoch+1} / {epochs} | validation_accs = {valid_accs / total} & validation_loss = {valid_loss / total}')\n",
    "\n",
    "torch.save(model.state_dict(), './checkpoints/proj1_baseline.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d6cc6c7-35a2-47b5-845f-0d508792e8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00, 11.70it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        imgs = batch\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, preds= torch.max(outputs, 1)\n",
    "        preds_list += preds.tolist()\n",
    "\n",
    "name = sorted(os.listdir(\"retina-test\"))\n",
    "for i in range(len(name)):\n",
    "    name[i], _ = name[i].split('.')\n",
    "\n",
    "submission ={\"image\" : name, \"level\" : preds_list}\n",
    "file = pd.DataFrame(submission)\n",
    "file.to_csv(\"submission1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108fb84-d793-4bd9-9817-5a1f18aee3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
